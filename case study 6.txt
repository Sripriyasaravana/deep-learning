import librosa
import numpy as np
import torch
from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer
import requests
import soundfile as sf
import os

# 1Ô∏è‚É£ Function: Download a Proper Sample Audio (.wav)
def download_sample_audio():
    url = "https://github.com/Jakobovski/free-spoken-digit-dataset/raw/master/recordings/0_jackson_0.wav"
    r = requests.get(url)
    with open("sample.wav", "wb") as f:
        f.write(r.content)
    print("‚úÖ Sample audio file downloaded successfully: sample.wav")
    return "sample.wav"

# 2Ô∏è‚É£ Audio Preprocessing
def preprocess_audio(file_path):
    y, sr = librosa.load(file_path, sr=16000)  # Resample to 16 kHz
    return y, sr

# 3Ô∏è‚É£ Load Pretrained Model (English)
def load_model():
    model_name = "facebook/wav2vec2-base-960h"
    print("üì¶ Loading model:", model_name)
    tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)
    model = Wav2Vec2ForCTC.from_pretrained(model_name)
    model.eval()
    return tokenizer, model

# 4Ô∏è‚É£ Transcription Function
def transcribe_audio(file_path, tokenizer, model):
    y, sr = preprocess_audio(file_path)
    inputs = tokenizer(y, return_tensors="pt", padding="longest")

    with torch.no_grad():
        logits = model(input_values=inputs.input_values).logits

    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = tokenizer.batch_decode(predicted_ids)
    return transcription[0]

# 5Ô∏è‚É£ Main Logic
def main():
    print("üé§ Speech-to-Text Transcription System")
    choice = input("Type 'sample' to use test audio or 'path' to use your own .wav file: ").strip().lower()

    if choice == "sample":
        file_path = download_sample_audio()
    else:
        file_path = input("Enter full path of your .wav file: ").strip()
        if not os.path.exists(file_path):
            print("‚ùå File not found. Please check your path.")
            return

    tokenizer, model = load_model()

    print("\nüîç Processing audio...")
    try:
        transcription = transcribe_audio(file_path, tokenizer, model)
        print("\nüó£Ô∏è Transcription:\n", transcription)
    except Exception as e:
        print("\n‚ùå Error while processing audio:", e)

if __name__ == "__main__":
    main()

	
