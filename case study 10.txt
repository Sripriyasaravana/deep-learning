# Install required libraries
# !pip install tweepy tensorflow keras nltk networkx matplotlib scikit-learn

import re
import nltk
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# -----------------------------
# 1. Simulated Twitter Data
# -----------------------------
tweets = [
    "I love the new product! It's amazing ðŸ˜",
    "Not happy with the product, it broke in one day!",
    "This is the best launch ever.",
    "The product is okay, nothing special.",
    "Terrible quality and slow support.",
    "Iâ€™m impressed with the new features!",
]

labels = [1, 0, 1, 0, 0, 1]  # 1=positive, 0=negative

# -----------------------------
# 2. Preprocess Tweets
# -----------------------------
nltk.download('stopwords')
from nltk.corpus import stopwords
stop = set(stopwords.words('english'))

def clean_tweet(text):
    text = re.sub(r"http\S+|@\S+|#\S+", "", text)
    text = re.sub(r"[^a-zA-Z\s]", "", text.lower())
    return " ".join([w for w in text.split() if w not in stop])

cleaned_tweets = [clean_tweet(t) for t in tweets]

# -----------------------------
# 3. Tokenization and Padding
# -----------------------------
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(cleaned_tweets)
X = tokenizer.texts_to_sequences(cleaned_tweets)
X = pad_sequences(X, maxlen=10, padding='post')

y = np.array(labels)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# -----------------------------
# 4. RNN (LSTM) Model
# -----------------------------
model = Sequential([
    Embedding(input_dim=5000, output_dim=64, input_length=10),
    LSTM(64, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

model.fit(X_train, y_train, epochs=10, batch_size=2, validation_split=0.2)

# -----------------------------
# 5. Sentiment Predictions
# -----------------------------
pred_probs = model.predict(X)
pred_labels = (pred_probs > 0.5).astype(int).flatten()

for t, p in zip(tweets, pred_labels):
    sentiment = "Positive" if p == 1 else "Negative"
    print(f"{t} â†’ {sentiment}")

# -----------------------------
# 6. Build Network Graph
# -----------------------------
# Example: nodes are tweets, edges connect tweets with similar sentiment
G = nx.Graph()

for i, tweet in enumerate(tweets):
    G.add_node(i, label=tweet, sentiment=pred_labels[i])

# Connect tweets with same sentiment
for i in range(len(tweets)):
    for j in range(i + 1, len(tweets)):
        if pred_labels[i] == pred_labels[j]:
            G.add_edge(i, j)

# -----------------------------
# 7. Visualize Network
# -----------------------------
pos = nx.spring_layout(G)
colors = ['green' if G.nodes[i]['sentiment'] == 1 else 'red' for i in G.nodes]

plt.figure(figsize=(8, 6))
nx.draw(G, pos, with_labels=True, node_color=colors, node_size=800, font_size=8)
labels_dict = {i: f"{'ðŸ˜Š' if G.nodes[i]['sentiment']==1 else 'ðŸ˜¡'}" for i in G.nodes}
nx.draw_networkx_labels(G, pos, labels=labels_dict)
plt.title("Tweet Sentiment Network Graph")
plt.show()
